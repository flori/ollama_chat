---
proxy: null # http://localhost:8080
model:
  name: <%= OllamaChat::EnvConfig::OLLAMA::CHAT::MODEL %>
  options:
    num_ctx: 8192
timeouts:
  connect_timeout: null
  read_timeout: 300
  write_timeout: 300
location:
  enabled: false
  name: Berlin
  decimal_degrees: [ 52.514127, 13.475211 ]
  units: SI (International System of Units) # or USCS (United States Customary System)
prompts:
  embed: "This source was now embedded: %{source}"
  summarize: |
    Generate an abstract summary of the content in this document using
    %{words} words:

    %{source_content}
  web_embed: |
    Answer the the query %{query} using the provided chunks.
  web_import: |
    Answer the the query %{query} using these imported sources:

    %{results}
  web_summarize: |
    Answer the the query %{query} using these summarized sources:

    %{results}
  location: You are at %{location_name}, %{location_decimal_degrees}, on %{localtime}, preferring %{units}
system_prompts:
  default: <%= OllamaChat::EnvConfig::OLLAMA::CHAT::SYSTEM || 'null' %>
  assistant: You are a helpful assistant.
voice:
  enabled: false
  default: Samantha
  list: <%= `say -v '?' 2>/dev/null`.lines.map { |l| l.force_encoding('ASCII-8BIT'); l[/^(.+?)\s+[a-z]{2}_[a-zA-Z0-9]{2,}/, 1] }.uniq.sort.to_s %>
markdown: true
stream: true
document_policy: importing
think:
  mode: disabled
  loud: true
context:
  format: JSON
embedding:
  enabled: true
  paused: false
  model:
    name: mxbai-embed-large
    embedding_length: 1024
    options: {}
    # Retrieval prompt template:
    prompt: 'Represent this sentence for searching relevant passages: %s'
  batch_size: 10
  database_filename: null # ':memory:'
  collection: <%= OllamaChat::EnvConfig::OLLAMA::CHAT::COLLECTION %>
  found_texts_size: 4096
  found_texts_count: 10
  splitter:
    name: RecursiveCharacter
    chunk_size: 1024
cache: Documentrix::Documents::SQLiteCache
redis:
  documents:
    url: <%= OllamaChat::EnvConfig::OLLAMA::REDIS_URL %>
  expiring:
    url: <%= OllamaChat::EnvConfig::OLLAMA::REDIS_EXPIRING_URL %>
    ex: 86400
working_dir_dependent_socket: true
request_headers:
  Accept: 'text/*,application/*,image/*'
ssl_no_verify: []
copy: ctc # Copy stdin to clipboard app
web_search:
  use: duckduckgo
  engines:
    duckduckgo:
      url: 'https://www.duckduckgo.com/html/?q=%{query}'
    searxng:
      url: <%= OllamaChat::EnvConfig::OLLAMA::SEARXNG_URL %>
vim:
  clientserver: socket
tools:
  get_current_weather:
    station_id: '00433'
    default: false
  get_cve:
    url: 'https://cveawg.mitre.org/api/cve/%{cve_id}'
    default: false
  get_endoflife:
    url: "https://endoflife.date/api/v1/products/%{product}"
    default: false
  get_location:
    default: true
  file_context:
    default: false
    confirm: true
  directory_structure:
    default: false
    confirm: true
    exclude:
      - corpus
      - pkg
  execute_grep:
    default: true
    cmd: 'grep -m %{max_results} -r %{pattern} %{path}'
  browse:
    default: false
  write_file:
    default: false
    confirm: true
    allowed:
      - ./tmp
  read_file:
    default: false
    confirm: false
    allowed:
      - ./tmp
      - ./lib
      - ./spec
  search_web:
    default: true
  import_url:
    default: true
    confirm: true
  gem_path_lookup:
    default: true
  vim_open_file:
    default: true
  run_tests:
    confirm: true
    default: true
